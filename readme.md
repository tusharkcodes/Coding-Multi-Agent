# ğŸ¤– Multi-Agent AI Software Development Framework (AutoGen)

## ğŸ“Œ Overview

This project is a **Multi-Agent AI framework built using AutoGen**, where multiple specialized agents powered by **Mistral LLM (via Ollama)** collaboratively simulate a real-world software development lifecycle.

From a single natural-language requirement, the system generates:

* Structured requirements
* Production-ready Python code
* Code reviews and iterations
* Documentation
* Test cases
* Deployment instructions

---

## ğŸ§  Agents in the System

* **Requirement Analysis Agent** â€“ Converts user input into structured software requirements
* **Coding Agent** â€“ Generates clean and modular Python code
* **Code Review Agent** â€“ Reviews code and approves or requests improvements
* **Documentation Agent** â€“ Produces clear technical documentation
* **Test Case Generation Agent** â€“ Creates unit and integration tests
* **Deployment Configuration Agent** â€“ Generates setup and run instructions
* **Streamlit UI Agent** â€“ Provides a UI to interact with the multi-agent pipeline

Agents are coordinated using **RoundRobinGroupChat** or **SelectorGroupChat** for iterative workflows.

---

## ğŸ› ï¸ Tech Stack

* Python 3.10+
* AutoGen (Multi-Agent Orchestration)
* Mistral LLM (via Ollama)
* Streamlit (UI)
* AsyncIO

---

## ğŸ“‚ Project Structure

```
Multi-Agent-Autogen/
â”‚
â”œâ”€â”€ agents/                 # All agent definitions
â”‚   â”œâ”€â”€ requirement_agent.py
â”‚   â”œâ”€â”€ coding_agent.py
â”‚   â”œâ”€â”€ review_agent.py
â”‚   â”œâ”€â”€ documentation_agent.py
â”‚   â”œâ”€â”€ test_agent.py
â”‚   â””â”€â”€ deployment_agent.py
â”‚
â”œâ”€â”€ tools/                  # Optional tool definitions
â”‚   â””â”€â”€ file_tools.py
â”‚
â”œâ”€â”€ models.py               # LLM configuration (Ollama / Mistral)
â”œâ”€â”€ app.py                  # Streamlit UI
â”œâ”€â”€ main.py                 # GroupChat orchestration
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/multi-agent-autogen.git
cd multi-agent-autogen
```

---

### 2ï¸âƒ£ Create Virtual Environment

```bash
python3 -m venv multi-agent
source multi-agent/bin/activate  # macOS/Linux
# multi-agent\Scripts\activate  # Windows
```

---

### 3ï¸âƒ£ Install Required Libraries

```bash
pip install --upgrade pip
pip install autogen-agentchat autogen-core autogen-ext
pip install asyncio tiktoken openai streamlit ollama
```

Or using `requirements.txt`:

```bash
pip install -r requirements.txt
```

---

## ğŸ¦™ Ollama & Mistral Setup

### 4ï¸âƒ£ Install Ollama

Download and install Ollama from:

ğŸ‘‰ [https://ollama.com/download](https://ollama.com/download)

---

### 5ï¸âƒ£ Pull Mistral Model

```bash
ollama pull mistral
```

Ensure Ollama is running:

```bash
ollama serve
```

---

## ğŸš€ Running the Project

### Run Multi-Agent Pipeline

```bash
python main.py
```

---

### Run Streamlit UI

```bash
streamlit run app.py
```

Then open the browser at:

```
http://localhost:8501
```

---

## ğŸ” Multi-Agent Flow

1. User enters requirement
2. Requirement agent structures it
3. Coding agent generates code
4. Review agent validates or requests changes
5. Documentation and tests are generated
6. Deployment instructions are produced

---

## ğŸ¯ Key Highlights

* Fully local LLM inference using **Mistral + Ollama**
* Iterative agent collaboration
* Real-world software engineering simulation
* Clean separation of concerns
* Beginner-friendly AutoGen implementation

---


## ğŸ Conclusion

This project demonstrates how **LLM-powered agents can collaborate like a real engineering team**, making it a strong foundation for learning **multi-agent systems, AutoGen, and applied Generative AI**.
